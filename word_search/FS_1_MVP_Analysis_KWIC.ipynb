{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16dc89c3",
   "metadata": {},
   "source": [
    "# üöÄ Analyse 2: Keyword in Context (KWIC) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8450ca1-0540-40e2-a0bf-0b360c887400",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b> üîî Feinlernziel(e) dieses Kapitels</b></br>\n",
    "   Sie k√∂nnen die Darstellungsmethode <i>Keywords in Context</i> beschreiben, W√∂rter zur Anzeige ausw√§hlen und diese anzeigen lassen.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dbd795-a35a-4cb5-898d-065094c4ef77",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Hinweise zur Ausf√ºhrung des Notebooks\n",
    "Dieses **Notebook** kann auf unterschiedlichen Levels erarbeitet werden (siehe Abschnitt [\"Technische Voraussetzungen\"](../markdown/introduction_requirements)): \n",
    "1. Book-Only Mode\n",
    "2. Cloud Mode: Daf√ºr auf üöÄ klicken und z.B. in Colab ausf√ºhren.\n",
    "3. Local Mode: Daf√ºr auf Herunterladen ‚Üì klicken und \".ipynb\" w√§hlen. \n",
    "\n",
    "## √úbersicht \n",
    "Im Folgenden werden die annotierten Dateien (CSV-Format) analysiert. Unser Ziel ist es, den annotierten Korpus zu nutzen, um KWIC-Ausgaben zu erzeugen.\n",
    "\n",
    "Daf√ºr werden folgendene Schritte durchgef√ºhrt:\n",
    "1. Einlesen des Korpus, der Metadaten und der Grippe-Wortliste\n",
    "2. Extraktion und Darstellung der Wortkontexte durch KWIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773264cc-9ee1-4ebe-a5db-427550c2fc74",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "  \n",
    "<b>Voraussetzungen zur Ausf√ºhrung des Jupyter Notebooks</b>\n",
    "<ol>\n",
    "<li> Installieren der Bibliotheken </li>\n",
    "<li> Pfad zu den Daten setzen</li>\n",
    "<li> Laden der Daten (z.B. √ºber den Command `wget` (s.u.))</li>\n",
    "</ol>\n",
    "Zum Testen: Ausf√ºhren der Zelle \"load libraries\" und der Sektion \"Einlesen der Daten\". </br>\n",
    "Alle Zellen, die mit üöÄ gekennzeichnet sind, werden nur bei der Ausf√ºhrung des Noteboos in Colab / JupyterHub bzw. lokal ausgef√ºhrt. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589dae0-5c0b-4e6a-ba3e-1beb826e2ea5",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "#  üöÄ Install libraries \n",
    "! pip install pandas bokeh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc18f5",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "## for interactivity in jupyter books\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.layouts import column, layout\n",
    "from bokeh.models import  ColumnDataSource, DataTable, DateFormatter, TableColumn\n",
    "# Ensure Bokeh output is displayed in the notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2803c9-99dc-49a3-b53d-7e4fa36bdee7",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1. Einlesen der Daten, Metadaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc74a1-204d-4fbd-9d99-cfba4cbd0d5d",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 1.1 Einlesen des Korpus (CSV-Dateien)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4b4cd4-d365-4b0f-b914-d243bf8af531",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "Zuerst wird der Ordner angelegt, in dem die CSV-Dateien gespeichert werden. Der Einfachheit halber wird die gleich Datenablagestruktur wie in dem <a href=\"https://github.com/dh-network/quadriga/tree/main\">GitHub Repository</a>, in dem die Daten gespeichert sind, vorausgesetzt. </br>\n",
    "Danach werden alle CSV-Dateien im Korpus heruntergeladen und gespeichert. Daf√ºr sind folgende Schritte n√∂tig:\n",
    "<ol>\n",
    "    <li>Es wird eine Liste erstellt, die die URLs zu den einzelnen CSV-Dateien beinhaltet.</li>\n",
    "    <li>Die Liste wird als txt-Datei gespeichert.</li>\n",
    "    <li>Alle Dateien aus der Liste werden heruntergeladen und in dem Ordner <i>../data/csv</i> gespeichert.</li>\n",
    "</ol>\n",
    "Sollten die Dateien schon an einem anderen Ort vorhanden sein, k√∂nnen die Dateipfade zu den Ordnern angepasst werden. </br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb0788-087e-47a9-b511-9fd3e30ce257",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Create data directory path\n",
    "corpus_dir = Path(\"../data/csv\")\n",
    "if not corpus_dir.exists():\n",
    "    corpus_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4db9e5-8000-40fa-98ef-fad638033397",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Create download list \n",
    "github_api_txt_dir_path = \"https://api.github.com/repos/dh-network/quadriga/contents/data/csv\"\n",
    "txt_dir_info = requests.get(github_api_txt_dir_path).json()\n",
    "url_list = [entry[\"download_url\"] for entry in txt_dir_info]\n",
    "\n",
    "# üöÄ Write download list as txt file\n",
    "url_list_path = Path(\"github_csv_file_urls.txt\")\n",
    "with url_list_path.open('w') as output_txt:\n",
    "    output_txt.write(\"\\n\".join(url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e458132-dd42-46dc-a059-4b9b1882e3c8",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è Only execute, if you haven't downloaded the files yet!\n",
    "# üöÄ Download all csv files ‚Äì this step will take a while (ca. 7 minutes)\n",
    "! wget -i github_csv_file_urls.txt -P ../data/csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65477d-db99-4a05-9415-ef94ecfc0470",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Setzen des Pfads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417616d",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the path to csv files to be processed\n",
    "csv_dir = Path(r\"../data/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645fa9f7",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create dictionary to save the corpus data (filenames and tables)\n",
    "corpus_annotations = {}\n",
    "\n",
    "# Iterate over csv files \n",
    "for file in csv_dir.iterdir():\n",
    "    # check if the entry is a file, not a directory\n",
    "    if file.is_file():\n",
    "        # check if the file has the correct suffix csv\n",
    "        if file.suffix == '.csv':\n",
    "            # read the csv table to a data frame\n",
    "            data = pd.read_csv(file) \n",
    "            # save the data frame to the dictionary, key=filename (without suffix), value=dataframe\n",
    "            corpus_annotations[file.name] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d12ee3-c58f-4710-8315-c15b8c9c2157",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 1.2 Einlesen der Metadaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681a7e78-498d-4636-981e-40dd1d030f96",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "Zuerst wird der Ordner angelegt, in dem die Metadaten-Datei gespeichert wird. Wieder wird die gleich Datenablagestruktur wie in dem <a href=\"https://github.com/dh-network/quadriga/tree/main\">GitHub Repository</a> vorausgesetzt. </br>\n",
    "Der Text wird aus GitHub heruntergeladen und in dem Ordner <i>../data/metadata/</i> abgespeichert. </br>\n",
    "Der Pfad kann in der Variable <i>metadata_path</i> angepasst werden. Die einzulesende Datei muss die Endung `.csv` haben. </br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd8b23-78c9-47b7-8eeb-b3fd68eefba0",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Create metadata directory path\n",
    "metadata_dir = Path(\"../data/metadata\")\n",
    "if not metadata_dir.exists():\n",
    "    metadata_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063358ac-df4b-4db8-a290-6cd6f0a2c636",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Load the metadata file from GitHub \n",
    "! wget https://raw.githubusercontent.com/dh-network/quadriga/refs/heads/main/data/metadata/QUADRIGA_FS-Text-01_Data01_Corpus-Table.csv -P ../data/metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb88bfb",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set path to metadata file\n",
    "metadata_path = '../data/metadata/QUADRIGA_FS-Text-01_Data01_Corpus-Table.csv'\n",
    "\n",
    "# read metadata file to pandas dataframe and set index\n",
    "corpus_metadata = pd.read_csv(metadata_path, sep=';')\n",
    "corpus_metadata = corpus_metadata.set_index('DC.identifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b001466c",
   "metadata": {},
   "source": [
    "#### Kombinieren von tokenisierten Texten und deren Metadaten f√ºr KWIC-Suche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_metadata(txtname, corpus_metadata):  \n",
    "    date = corpus_metadata.loc[txtname, 'DC.date']\n",
    "    date = str(date)\n",
    "    year = date[:4]\n",
    "    month = date[:7]\n",
    "    day = date\n",
    "    return year, month, day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7b7afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, annotated_text in corpus_annotations.items():\n",
    "    txtname = filename.replace('.csv', '')\n",
    "    if txtname in corpus_metadata.index:\n",
    "        year, month, day = get_date_metadata(txtname, corpus_metadata)\n",
    "        annotated_text['month'] = month\n",
    "        annotated_text['filename'] = filename\n",
    "search_df = pd.concat(corpus_annotations.values())\n",
    "search_df = search_df.reset_index()\n",
    "search_df[\"Token\"] = search_df[\"Token\"].astype(str)\n",
    "print(f'The KWIC-search will be over a corpus of {search_df.shape[0]} word occurences')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708ede0f",
   "metadata": {},
   "source": [
    "### 1.3 Einlesen der Wortliste (Semantisches Feld \"Grippe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db853c1",
   "metadata": {
    "tags": [
     "skip-execution",
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Create word list directory path\n",
    "wordlist_dir = Path(\"../data/wordlist\")\n",
    "if not wordlist_dir.exists():\n",
    "    wordlist_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9394def",
   "metadata": {
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Load the wordlist file from GitHub \n",
    "! wget https://raw.githubusercontent.com/dh-network/quadriga/refs/heads/main/data/wordlist/grippe.txt -P ../data/wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8461a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_wordlist = Path(\"../data/wordlist/grippe.txt\")\n",
    "word_list = path_to_wordlist.read_text().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d41f01",
   "metadata": {},
   "source": [
    "Wie sieht die Wortliste aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8940ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a2a08b",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2.  Extraktion und Darstellung der Wortkontexte durch KWIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9684f03",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "class ContextViewer:\n",
    "    \n",
    "    def __init__(self, search_df):\n",
    "        self.full_df = search_df\n",
    "        print(f'Searching in a corpus of {self.full_df.shape[0]} word occurences')\n",
    "        \n",
    "    def show_kwic_output(self, search_terms, n_words):\n",
    "        contexts_df = self.get_context_words(search_terms, n_words)\n",
    "        \n",
    "        # Convert DataFrame to ColumnDataSource\n",
    "        source = ColumnDataSource(contexts_df)\n",
    "                \n",
    "        # Create Table Columns\n",
    "        columns = [TableColumn(field=col, title=col) for col in contexts_df.columns]\n",
    "\n",
    "        # Create DataTable\n",
    "        data_table = DataTable(source=source, columns=columns)\n",
    "\n",
    "        # Display DataTable\n",
    "        output_notebook()  # Use this to render in Jupyter Notebook\n",
    "        show(layout([data_table]))\n",
    "\n",
    "    \n",
    "    def get_context_words(self, search_terms, n_words):\n",
    "        #search_terms = input('Insert a word to search, split by comma if more than one: ')\n",
    "        if len(search_terms) == 0:\n",
    "            search_terms = word_list\n",
    "        if isinstance(search_terms, str):\n",
    "            search_terms = search_terms.split(',')\n",
    "        search_terms = [x.strip() for x in search_terms]\n",
    "        indices = self.full_df.query(f'Lemma.isin({search_terms})').index\n",
    "        #print(indices)\n",
    "        left_contexts = []\n",
    "        this_words = []\n",
    "        right_contexts = []\n",
    "        months = []\n",
    "        for indice in indices:\n",
    "            left = self.full_df.iloc[indice-n_words:indice-1, ][\"Token\"]\n",
    "            left—Å = left[~left.str.contains('\\n')]\n",
    "            right = self.full_df.iloc[indice+1:indice+n_words, ][\"Token\"]\n",
    "            right—Å = right[~right.str.contains('\\n')]\n",
    "            left_contexts.append(' '.join(left—Å))\n",
    "            right_contexts.append(' '.join(right—Å))\n",
    "            this_words.append(self.full_df.iloc[indice, ][\"Token\"])\n",
    "            months.append(self.full_df.iloc[indice, ][\"month\"])\n",
    "        newdf = pd.DataFrame()\n",
    "        newdf['left_context'] = left_contexts\n",
    "        newdf['word'] = this_words\n",
    "        newdf['right_context'] = right_contexts\n",
    "        newdf['month'] = months\n",
    "        return newdf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec93d66",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwic = ContextViewer(search_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e2f1c7",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwic.show_kwic_output(word_list, n_words=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb3a75",
   "metadata": {},
   "source": [
    "### Worteingabe f√ºr die Suche und KWIC-output (f√ºr Cloud Mode und Local Mode) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c007a92",
   "metadata": {
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "text_input = input(\"Geben Sie die zu suchenden W√∂rter ein und trennen Sie sie durch Kommas, wenn es mehrere sind:\")\n",
    "# Convert the input to a list by splitting the input by comma\n",
    "search_terms = [x.strip() for x in text_input.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea89110",
   "metadata": {
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "kwic.show_kwic_output(search_terms, n_words=5)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
