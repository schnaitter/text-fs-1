{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7583a095-80ca-4c27-b4fe-99f8a83e7022",
   "metadata": {},
   "source": [
    "# üöÄ Analyse 1: Diachrone Frequenzdiagramme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4affd58b-2121-43f4-9b77-4ba5e72fe68f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b> üîî Feinlernziel(e) dieses Kapitels</b></br>\n",
    "   Sie k√∂nnen die notwendigen Schritte zur Frequenzanalyse eines semantischen Felds aufz√§hlen, Unterschiede in der Berechnung der H√§ufigkeiten benennen und die Ergebnisse reflektieren.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc89c3",
   "metadata": {},
   "source": [
    "## Hinweise zur Ausf√ºhrung des Notebooks\n",
    "Dieses **Notebook** kann auf unterschiedlichen Levels erarbeitet werden (siehe Abschnitt [\"Technische Voraussetzungen\"](../markdown/introduction_requirements)): \n",
    "1. Book-Only Mode\n",
    "2. Cloud Mode: Daf√ºr auf üöÄ klicken und z.B. in Colab ausf√ºhren.\n",
    "3. Local Mode: Daf√ºr auf Herunterladen ‚Üì klicken und \".ipynb\" w√§hlen. \n",
    "\n",
    "## √úbersicht \n",
    "Im Folgenden werden die annotierten Dateien (CSV-Format) analysiert. Unser Ziel ist es, die Wort-/Lemma-H√§ufigkeiten einer vordefinierten Wortgruppe f√ºr die Monate des Jahres 1918 zu plotten und zu sehen, ob sie mit den Wellen der Grippepandemie korrelieren.\n",
    "Daf√ºr werden folgendene Schritte durchgef√ºhrt:\n",
    "1. Einlesen des Korpus, der Metadaten und der Grippe-Wortliste\n",
    "2. Extraktion der Worth√§ufigkeiten und Plotten der Worth√§ufigkeiten\n",
    "3. Diskussion der Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335d2b5-e7f0-4fe1-8dbf-2b5ea3336e9f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "  \n",
    "<b>Voraussetzungen zur Ausf√ºhrung des Jupyter Notebooks</b>\n",
    "<ol>\n",
    "<li> Installieren der Bibliotheken </li>\n",
    "<li> Pfad zu den Daten setzen</li>\n",
    "<li> Laden der Daten (z.B. √ºber den Command `wget` (s.u.))</li>\n",
    "</ol>\n",
    "Zum Testen: Ausf√ºhren der Zelle \"load libraries\" und der Sektion \"Einlesen der Daten\". </br>\n",
    "Alle Zellen, die mit üöÄ gekennzeichnet sind, werden nur bei der Ausf√ºhrung des Noteboos in Colab / JupyterHub bzw. lokal ausgef√ºhrt. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5f0950-05d1-4fda-9bad-eca989d2d75b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "#  üöÄ Install libraries \n",
    "! pip install pandas bokeh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec0c33",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# for interactivity in jupyter books\n",
    "#from bokeh.application import Application\n",
    "#from bokeh.application.handlers import FunctionHandler\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.models import ColumnDataSource, CustomJS, TextInput, Div, RadioButtonGroup, Switch\n",
    "# Ensure Bokeh output is displayed in the notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc0959-7087-4353-9c17-665013944436",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1. Einlesen der Daten, Metadaten und der Grippe-Wortliste\n",
    "Um eine/mehrere Dateien mit Python bearbeiten zu k√∂nnen, m√ºssen die Dateien zuerst ausgew√§hlt werden, d.h der [Pfad](https://en.wikipedia.org/wiki/Path_(computing)) zu den Dateien wird gesetzt, und dann eingelesen werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7908f6a-c408-4a4a-a769-114c99d01f4a",
   "metadata": {},
   "source": [
    "### 1.1 Einlesen des Korpus (CSV-Dateien)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5185fdd6-56a5-442e-a2ad-47367a2dd47e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "Zuerst wird der Ordner angelegt, in dem die CSV-Dateien gespeichert werden. Der Einfachheit halber wird die gleich Datenablagestruktur wie in dem <a href=\"https://github.com/dh-network/quadriga/tree/main\">GitHub Repository</a>, in dem die Daten gespeichert sind, vorausgesetzt. </br>\n",
    "Danach werden alle CSV-Dateien im Korpus heruntergeladen und gespeichert. Daf√ºr sind folgende Schritte n√∂tig:\n",
    "<ol>\n",
    "    <li>Es wird eine Liste erstellt, die die URLs zu den einzelnen CSV-Dateien beinhaltet.</li>\n",
    "    <li>Die Liste wird als txt-Datei gespeichert.</li>\n",
    "    <li>Alle Dateien aus der Liste werden heruntergeladen und in dem Ordner <i>../data/csv</i> gespeichert.</li>\n",
    "</ol>\n",
    "Sollten die Dateien schon an einem anderen Ort vorhanden sein, k√∂nnen die Dateipfade zu den Ordnern angepasst werden. </br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d9d65e-ef79-42fb-aba4-7ca0e97d8aa4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Create data directory path\n",
    "corpus_dir = Path(\"../data/csv\")\n",
    "if not corpus_dir.exists():\n",
    "    corpus_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d6fdd-7226-431f-a3ab-9ba54da7a7ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Create download list \n",
    "github_api_txt_dir_path = \"https://api.github.com/repos/dh-network/quadriga/contents/data/csv\"\n",
    "txt_dir_info = requests.get(github_api_txt_dir_path).json()\n",
    "url_list = [entry[\"download_url\"] for entry in txt_dir_info]\n",
    "\n",
    "# üöÄ Write download list as txt file\n",
    "url_list_path = Path(\"github_csv_file_urls.txt\")\n",
    "with url_list_path.open('w') as output_txt:\n",
    "    output_txt.write(\"\\n\".join(url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8d4d3-3e95-4e58-a90c-8fb9497b595c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è Only execute, if you haven't downloaded the files yet!\n",
    "# üöÄ Download all csv files ‚Äì this step will take a while (ca. 7 minutes)\n",
    "! wget -i github_csv_file_urls.txt -P ../data/csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad360f6-7453-4f39-99f7-7794608ff0a7",
   "metadata": {},
   "source": [
    "Setzen des Pfads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417616d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the path to csv files to be processed\n",
    "csv_dir = Path(r\"../data/csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22863d76-5258-4b08-b29c-40b302200be3",
   "metadata": {},
   "source": [
    "Einlesen der CSV-Dateien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645fa9f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create dictionary to save the corpus data (filenames and tables)\n",
    "corpus_annotations = {}\n",
    "\n",
    "# Iterate over csv files \n",
    "for file in csv_dir.iterdir():\n",
    "    # check if the entry is a file, not a directory\n",
    "    if file.is_file():\n",
    "        # check if the file has the correct suffix csv\n",
    "        if file.suffix == '.csv':\n",
    "            # read the csv table to a data frame\n",
    "            data = pd.read_csv(file) \n",
    "            # save the data frame to the dictionary, key=filename (without suffix), value=dataframe\n",
    "            corpus_annotations[file.with_suffix(\"\").name] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75504fd3-3dca-4655-b169-51ba5f9b3ea8",
   "metadata": {},
   "source": [
    "Wie viele Dateien wurden eingelesen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423cc59-a628-4b00-b054-55a60716c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e848450-4bc0-4073-a7f1-e61e848188fb",
   "metadata": {},
   "source": [
    "Wie sieht der Anfang der ersten Datei aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e65bc1-39b2-44d8-b629-c40ef4c668b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_annotations[list(corpus_annotations.keys())[0]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f49ed40-f735-4856-9b9d-0c60222b0778",
   "metadata": {},
   "source": [
    "### 1.2 Einlesen der Metadaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3428c9d8-5b4b-4f25-b286-b8f18dcde33b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "Zuerst wird der Ordner angelegt, in dem die Metadaten-Datei gespeichert wird. Wieder wird die gleich Datenablagestruktur wie in dem <a href=\"https://github.com/dh-network/quadriga/tree/main\">GitHub Repository</a> vorausgesetzt. </br>\n",
    "Der Text wird aus GitHub heruntergeladen und in dem Ordner <i>../data/metadata/</i> abgespeichert. </br>\n",
    "Der Pfad kann in der Variable <i>metadata_path</i> angepasst werden. Die einzulesende Datei muss die Endung `.csv` haben. </br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e236b6-ff73-4227-b8cb-180a8737f95f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Create metadata directory path\n",
    "metadata_dir = Path(\"../data/metadata\")\n",
    "if not metadata_dir.exists():\n",
    "    metadata_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa5ade-eee2-48dc-81bb-2b84a2ceac16",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Load the metadata file from GitHub \n",
    "! wget https://raw.githubusercontent.com/dh-network/quadriga/refs/heads/main/data/metadata/QUADRIGA_FS-Text-01_Data01_Corpus-Table.csv -P ../data/metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb88bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to metadata file\n",
    "metadata_path = '../data/metadata/QUADRIGA_FS-Text-01_Data01_Corpus-Table.csv'\n",
    "\n",
    "# read metadata file to pandas dataframe\n",
    "corpus_metadata = pd.read_csv(metadata_path, sep=';')\n",
    "corpus_metadata['DC.date'] = pd.to_datetime(corpus_metadata['DC.date'])\n",
    "#corpus_metadata = corpus_metadata.set_index('DC.identifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d414bb4f-4b88-47ce-977a-9f9cf7cdd0ab",
   "metadata": {},
   "source": [
    "Wie sieht die Metadaten-Datei aus? (erste f√ºnf Zeilen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b09b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5bf4b-bd61-4745-82f1-f8b019309c8b",
   "metadata": {},
   "source": [
    "### 1.3 Einlesen der Wortliste (Semantisches Feld \"Grippe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5b391-788a-4d98-9b27-4ab20750a659",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "Parallel zur Metadaten-Datei wird ein Ordner f√ºr die Wortlisten-Datein angelegt, die Datei wird aus GitHub geladen und in dem erstellten Ordner abgelegt.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0876d-44b2-464d-a210-33b68c71c380",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Create word list directory path\n",
    "wordlist_dir = Path(\"../data/wordlist\")\n",
    "if not wordlist_dir.exists():\n",
    "    wordlist_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b96b4e-7ea5-4277-89fc-6e6f76bd7de1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Load the wordlist file from GitHub \n",
    "! wget https://raw.githubusercontent.com/dh-network/quadriga/refs/heads/main/data/wordlist/grippe.txt -P ../data/wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deee84f-89e9-431d-9ce0-b4319e6bd12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_wordlist = Path(\"../data/wordlist/grippe.txt\")\n",
    "word_list = path_to_wordlist.read_text().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ad341f-b7af-4821-9b0f-a58c0d4b0d66",
   "metadata": {},
   "source": [
    "Wie sieht die Wortliste aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe88c8-c191-4dbd-a229-bb22aaea7391",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3da39",
   "metadata": {},
   "source": [
    "## 2. Suche nach einem Lemma und plotte die H√§ufigkeit\n",
    "\n",
    "1. Datum zu den Annotationen hinzuf√ºgen\n",
    "2. Annotationen in einer Datenstruktur (einem DataFrame) speichern\n",
    "3. Lemmata suchen und nach Zeitabschnitt gruppieren\n",
    "4. H√§ufigkeiten plotten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c635c3-1a5d-4fbe-9227-8880fd37e7ea",
   "metadata": {},
   "source": [
    "### 2.1 Datum zu den Annotationen hinzuf√ºgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df801ddb-a702-4f8f-aa77-10d0a310dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_to_corpus_annotations(corpus_metadata: pd.DataFrame, corpus_annotated: dict[str, pd.DataFrame]) -> None:\n",
    "    \"\"\"Add date colum from corpus_metadata to corpus annotated. Map by DC.identifier / filename.\"\"\"\n",
    "    for identifier, df in corpus_annotated.items():\n",
    "        if identifier in corpus_metadata[\"DC.identifier\"].values:\n",
    "            df[\"date\"] = corpus_metadata[corpus_metadata[\"DC.identifier\"] == identifier][\"DC.date\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb1604-59f5-4a23-bf4c-51439867ff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_date_to_corpus_annotations(corpus_metadata, corpus_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5608d910-a9e9-4227-8bba-9bc487535468",
   "metadata": {},
   "source": [
    "### 2.2 Annotationen in einer Datenstruktur (einem DataFrame) speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca540f02-c1cb-4648-aa10-a6d3a98b4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_annotations_merged = pd.concat(corpus_annotations.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a4b2e-f69b-444a-9599-7244aae132bc",
   "metadata": {},
   "source": [
    "### 2.3 Berechnen der absoluten und relativen H√§ufigkeiten zusammengefasst pro Tag, Woche und Monat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581c5d3-20b7-412a-97e6-9fd30f99dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_split_by_timeframe(merged_df: pd.DataFrame, search_terms=word_list) -> tuple[dict[str, pd.DataFrame], dict[str, pd.DataFrame]]:\n",
    "    \"\"\"Get lemmata count of words in search_terms by month, week and days.\n",
    "    Plot frequencies using plot_with_js function.\n",
    "    :param pd.DataFrame merged_df: The merged dataframe of all annotations\n",
    "    :param list search_terms: List of words to search in merged_df\n",
    "    :return tuple: Two dictionaries with identical keys, saving the absolute and relative frequencies by three time frames respectively\n",
    "    \"\"\"\n",
    "    # Filter dataframe by lemmata in word_list\n",
    "    result = merged_df.query(f'Lemma.isin({search_terms})')\n",
    "\n",
    "    # Collect lemmata count by time frames: month, week, day\n",
    "    frequency_parameters = [\"M\", \"W-MON\", \"D\"]\n",
    "    absolute_frequencies = {option: result.groupby(pd.PeriodIndex(result['date'], freq=option)).count().Lemma \n",
    "                            for option in frequency_parameters}\n",
    "\n",
    "    relative_frequencies = {}\n",
    "    for frequency_param in frequency_parameters:\n",
    "        relative_frequencies[frequency_param] = absolute_frequencies[frequency_param] / merged_df.groupby(pd.PeriodIndex(merged_df['date'], freq=frequency_param)).count().Lemma.fillna(0)\n",
    "\n",
    "    return absolute_frequencies, relative_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad9a9a9-ac93-48b4-902e-2cd272917d43",
   "metadata": {},
   "source": [
    "### 2.4 Erstellen eines interaktiven Liniendiagramms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5754de9-c0f5-450d-aa6d-1d6832330e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_js(merged_df: pd.DataFrame, search_terms=word_list) -> None:\n",
    "    \"\"\"\n",
    "    Get lemmata count of words in search_terms by month, week and days using search_split_by_timeframe\n",
    "    Interactively plot frequencies using bokeh and javascript callback. \n",
    "    :param pd.DataFrame merged_df: The merged dataframe of all annotations\n",
    "    :param list search_terms: List of words to search in merged_df\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get frequencies of lemmata in word_list by timeframe\n",
    "    absolute_frequencies, relative_frequencies = search_split_by_timeframe(merged_df, search_terms=search_terms)\n",
    "    \n",
    "    # Prepare data sources\n",
    "    absolute_sources = {key: dict(x=val.index, y=list(val)) for key, val in absolute_frequencies.items()}\n",
    "    relative_sources = {key: dict(x=val.index, y=list(val)) for key, val in relative_frequencies.items()}\n",
    "    \n",
    "    # Set month as default for the plot\n",
    "    line_source = ColumnDataSource(data=absolute_sources[\"M\"])\n",
    "\n",
    "    # Create a plot\n",
    "    p = figure(title=f\"Frequency of words {search_terms}\", x_axis_type=\"datetime\", x_axis_label='Time', \n",
    "               y_axis_label='Frequency', width=700, height=400)\n",
    "    line = p.line('x', 'y', source=line_source, line_width=2, color='blue')\n",
    "\n",
    "    # RadioButtonGroup to select mode\n",
    "    radio_button_group = RadioButtonGroup(labels=[\"Monthly\", \"Weekly\", \"Daily\"], active=0)\n",
    "    switch_title = Div(text=\"<b style='color: blue;'>Relative Frequencies:</b>\")\n",
    "    switch = Switch(active=False)\n",
    "\n",
    "    # Callback to update the data based on selected mode\n",
    "    callback = CustomJS(\n",
    "        args=dict(\n",
    "            line=line,\n",
    "            absolute_sources=absolute_sources,\n",
    "            relative_sources=relative_sources,\n",
    "            radio_button_group=radio_button_group,\n",
    "            switch_element=switch,  # rename this because \"switch\" is a keyword in JS\n",
    "        ),\n",
    "        code=\"\"\"                \n",
    "        // Access the value of the switch\n",
    "        const sources = switch_element.active ? relative_sources : absolute_sources;\n",
    "        \n",
    "        // Access the value of the RadioButtonGroup\n",
    "        const mode = radio_button_group.active;\n",
    "    \n",
    "        // Retrieve the selected frequency\n",
    "        const freq = [\"M\", \"W-MON\", \"D\"][mode];\n",
    "    \n",
    "        // update data source and emit change event\n",
    "        line.data_source.data = sources[freq];\n",
    "        line.data_source.change.emit();\n",
    "    \"\"\",\n",
    "    )\n",
    "\n",
    "    # Attach the callback to both widgets\n",
    "    radio_button_group.js_on_change('active', callback)\n",
    "    switch.js_on_change(\"active\", callback)\n",
    "\n",
    "    # Layout the RadioButtonGroup and plot\n",
    "    layout = column(row(radio_button_group, switch_title, switch), p)\n",
    "    show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b849a38d-372c-4999-8ea7-24503b6650c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to plot the frequencies \n",
    "plot_with_js(corpus_annotations_merged, search_terms=word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da05d1b1-fe97-4908-b358-0eeec8d13db4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Worteingabe f√ºr die Suche (f√ºr Cloud Mode und Local Mode) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4323c-84d9-4e64-a02f-ada533546de4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "text_input = input(\"Geben Sie die zu suchenden W√∂rter ein und trennen Sie sie durch Kommas, wenn es mehrere sind:\")\n",
    "# Convert the input to a list by splitting the input by comma\n",
    "text_input = [x.strip() for x in text_input.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b9eea3-4b4e-4003-be48-8ee0c31d7d2b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "plot_with_js(corpus_annotations_merged, search_terms=text_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffeb48a",
   "metadata": {},
   "source": [
    "## 3. Diskussion des Zwischenergebnisses\n",
    "\n",
    "Ist dieses Ergebnis sinnvoll und spiegelt es tats√§chlich etwas wider? Eine M√∂glichkeit, dies zu √ºberpr√ºfen, besteht darin, unser Diagramm mit den tats√§chlichen Daten √ºber die Intensit√§t der Pandemie zu vergleichen.\n",
    "\n",
    "In Taubenberger & Morens (2006) wird festgestellt, dass 'The first pandemic influenza wave appeared in the spring of 1918, followed in rapid succession by much more fatal second and third waves in the fall and winter of 1918‚Äì1919, respectively'('Die erste pandemische Influenza-Welle im Fr√ºhjahr 1918 auftrat, gefolgt von weitaus t√∂dlicheren zweiten und dritten Wellen im Herbst und Winter 1918‚Äì1919'). Sie erg√§nzen diese Aussage auch mit einem Diagramm aus einem fr√ºheren Papier (Jordanm 1927):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551cb63d",
   "metadata": {},
   "source": [
    "<img src=\"https://wwwnc.cdc.gov/eid/images/05-0979-F1.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ed9af",
   "metadata": {},
   "source": [
    "Unsere zwei Wellen der Erw√§hnungen des Wortes 'Grippe' scheinen den Sterblichkeitszahlen zu entsprechen, was darauf hindeuten k√∂nnte, dass die Methode, obwohl sehr einfach, funktioniert und dass historische Ereignisse manchmal in Wortfrequenzz√§hlungen reflektiert werden k√∂nnen... Die dritte Welle scheint nicht reproduziert zu werden, was eine weitere Untersuchung erfordert. Eine Hypothese k√∂nnte sein, dass, √§hnlich wie bei der COVID-Pandemie, neue Krankheitswellen irgendwann aufh√∂ren, die Aufmerksamkeit der √ñffentlichkeit zu erregen. Beispielsweise waren die COVID-Wellen im Jahr 2021 st√§rker als die im Jahr 2020, aber die Berichterstattung in den Nachrichten nahm bereits ab. Dies k√∂nnte besonders f√ºr Anfang 1919 zutreffen, als nach dem Verlust des Krieges und der Revolution von 1918 Grippetodesf√§lle kein Nachrichtenthema mehr waren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a431937-bbc7-47f1-840d-cab7b914da89",
   "metadata": {},
   "source": [
    "### Bibliographie\n",
    "* Jordan E. (1927). Epidemic influenza: a survey. Chicago: American Medical Association.\n",
    "* Taubenberger, J. K., & Morens, D. M. (2006). 1918 Influenza: the Mother of All Pandemics. Emerging Infectious Diseases, 12(1), 15-22. https://doi.org/10.3201/eid1201.050979"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
